{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T21:38:31.341169785Z",
     "start_time": "2023-12-03T21:38:31.300436402Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "from imports import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:38:31.784769728Z",
     "start_time": "2023-12-03T21:38:31.776914132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:36.895362689Z",
     "start_time": "2023-12-03T17:12:36.860381209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the saved datasets\n",
    "train_data = np.load('./fashion-mnist-processed-data/train_data.npy')\n",
    "val_data = np.load('./fashion-mnist-processed-data/val_data.npy')\n",
    "test_data = np.load('./fashion-mnist-processed-data/test_data.npy')\n",
    "\n",
    "train_targets = np.load('./fashion-mnist-processed-data/train_targets.npy')\n",
    "val_targets = np.load('./fashion-mnist-processed-data/val_targets.npy')\n",
    "test_targets = np.load('./fashion-mnist-processed-data/test_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, axis=1)\n",
    "val_data = np.expand_dims(val_data, axis=1)\n",
    "test_data = np.expand_dims(test_data, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:37.040207117Z",
     "start_time": "2023-12-03T17:12:37.032420541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Converting to tensors\n",
    "train_data, train_targets = torch.tensor(train_data, dtype=torch.float32), torch.tensor(train_targets, dtype=torch.long)\n",
    "val_data, val_targets = torch.tensor(val_data, dtype=torch.float32), torch.tensor(val_targets, dtype=torch.long)\n",
    "test_data, test_targets = torch.tensor(test_data, dtype=torch.float32), torch.tensor(test_targets, dtype=torch.long)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:37.266601508Z",
     "start_time": "2023-12-03T17:12:37.200593994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Normalizeing the data\n",
    "train_data = train_data/ 255.0\n",
    "val_data = val_data/255.0\n",
    "test_data = test_data/255.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:37.942661989Z",
     "start_time": "2023-12-03T17:12:37.863040025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Data loaders and set batch size for training, validation, testing\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(train_data, train_targets), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_data, val_targets), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_data, test_targets), batch_size=batch_size, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:38.097123489Z",
     "start_time": "2023-12-03T17:12:38.073228940Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "#Single layer CNN model\n",
    "class SingleLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleLayerCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:38.264748236Z",
     "start_time": "2023-12-03T17:12:38.255877915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "\n",
    "model = SingleLayerCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:12:38.417754072Z",
     "start_time": "2023-12-03T17:12:38.410890397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training accuracy: 96.73%, Validation Accuracy: 90.42%\n",
      "Epoch [2/10], Training accuracy: 96.41%, Validation Accuracy: 90.52%\n",
      "Epoch [3/10], Training accuracy: 96.97%, Validation Accuracy: 90.42%\n",
      "Epoch [4/10], Training accuracy: 96.91%, Validation Accuracy: 89.73%\n",
      "Epoch [5/10], Training accuracy: 97.16%, Validation Accuracy: 90.22%\n",
      "Epoch [6/10], Training accuracy: 97.51%, Validation Accuracy: 90.35%\n",
      "Epoch [7/10], Training accuracy: 98.22%, Validation Accuracy: 90.43%\n",
      "Epoch [8/10], Training accuracy: 97.92%, Validation Accuracy: 90.45%\n",
      "Epoch [9/10], Training accuracy: 98.30%, Validation Accuracy: 90.25%\n",
      "Epoch [10/10], Training accuracy: 98.30%, Validation Accuracy: 90.18%\n"
     ]
    }
   ],
   "source": [
    "# Training and validation for certain epochs\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_train = 0\n",
    "        correct_train = 0\n",
    "    \n",
    "        for images_train, labels_train in train_loader:\n",
    "            outputs_train = model(images_train)\n",
    "            _, predicted_train = torch.max(outputs_train.data, 1)\n",
    "            total_train += labels_train.size(0)\n",
    "            correct_train += (predicted_train == labels_train).sum().item()\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Training accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:19:41.032389203Z",
     "start_time": "2023-12-03T17:17:10.596182973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 9, Actual label: 9\n"
     ]
    }
   ],
   "source": [
    "# Prediction on a single item from test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(test_loader))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print(f'Predicted label: {predicted[0].item()}, Actual label: {labels[0].item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:19:41.049388334Z",
     "start_time": "2023-12-03T17:19:41.034077930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.55%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:19:41.782506959Z",
     "start_time": "2023-12-03T17:19:41.043440815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Now let us perform hyperparamter tuning to find optimal parameters and replace them where needed!\n",
    "# Defining the parametr grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [50, 100]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:32:00.608914945Z",
     "start_time": "2023-12-03T17:32:00.568535399Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Function to train and evaluate the model\n",
    "def train_val_evaluate(model, train_loader, val_loader, criterion, optimizer, epochs=3):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    return val_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:34:09.707527381Z",
     "start_time": "2023-12-03T17:34:09.690378543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'batch_size': 32, 'lr': 0.001}, Validation Accuracy: 89.78%\n",
      "Params: {'batch_size': 32, 'lr': 0.01}, Validation Accuracy: 88.42%\n",
      "Params: {'batch_size': 32, 'lr': 0.1}, Validation Accuracy: 55.72%\n",
      "Params: {'batch_size': 64, 'lr': 0.001}, Validation Accuracy: 90.00%\n",
      "Params: {'batch_size': 64, 'lr': 0.01}, Validation Accuracy: 87.30%\n",
      "Params: {'batch_size': 64, 'lr': 0.1}, Validation Accuracy: 81.40%\n",
      "Params: {'batch_size': 128, 'lr': 0.001}, Validation Accuracy: 89.40%\n",
      "Params: {'batch_size': 128, 'lr': 0.01}, Validation Accuracy: 89.12%\n",
      "Params: {'batch_size': 128, 'lr': 0.1}, Validation Accuracy: 10.00%\n",
      "Best Params: {'batch_size': 64, 'lr': 0.001}, Best Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "# Let us begin Hyperparameter tuning\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Update batch size for data loaders\n",
    "    train_loader = DataLoader(TensorDataset(train_data, train_targets), batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_data, val_targets), batch_size=params['batch_size'], shuffle=False)\n",
    "    model = SingleLayerCNN()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "    # Training and evaluating the model\n",
    "    accuracy = train_val_evaluate(model, train_loader, val_loader, criterion, optimizer, params['epochs'])\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "\n",
    "    print(f\"Params: {params}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(f\"Best Params: {best_params}, Best Accuracy: {best_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T17:42:37.556716817Z",
     "start_time": "2023-12-03T17:34:43.585669553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
